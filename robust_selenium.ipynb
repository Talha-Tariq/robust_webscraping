{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import requests, bs4\n",
    "import pandas as pd\n",
    "import proxyscrape\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from proxyscrape import create_collector, get_collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proxy Scraping Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_proxies(collector, timeout_filtering, url_testing):\n",
    "    \n",
    "    #Refresh list of proxies to scrape \n",
    "    collector.refresh_proxies(force=True)\n",
    "    \n",
    "    #Scrape HTTPS proxies that provide anonymity for specific countries. See proxyscrape documentation for more info.\n",
    "#     proxy_list = collector.get_proxy({'code': ('us'), 'anonymous': True, 'type': 'https'}) #Get one USA proxy\n",
    "#     proxy_list = collector.get_proxies({'code': ('us'), 'anonymous': True, 'type': 'https'}) #Get ALL USA proxies\n",
    "    proxy_list = collector.get_proxies({'code': ('us', 'ca'), 'anonymous': True, 'type': 'https'}) #Get ALL USA + Canadian proxies\n",
    "#     proxy_list = collector.get_proxies({'code': ('us', 'ca', 'de', 'fr'), 'anonymous': True, 'type': 'https'}) ALL USA+Canada+German+French\n",
    "    \n",
    "    #Let's extract useful information from this scraped list of proxies\n",
    "    #Note that scraped list may contain duplicates\n",
    "    \n",
    "    ip_addresses = []\n",
    "    ports = []\n",
    "    countries = []\n",
    "\n",
    "    #Collecting proxy information\n",
    "    for proxy in proxy_list:\n",
    "        if proxy[0] in ip_addresses and proxy[1] in ports: #preventing duplicates from being recorded\n",
    "            continue\n",
    "\n",
    "        ip_addresses.append(proxy[0]) #Collect the ip addresses\n",
    "        ports.append(proxy[1]) #Collect the port numbers\n",
    "        countries.append(proxy[3]) #Collect their corresponding countries\n",
    "    \n",
    "    #Now let's filter out the working (good) proxies\n",
    "    \n",
    "    good_proxies = [] \n",
    "    good_proxies_country = []\n",
    "\n",
    "    for ip_address, port, country in zip(ip_addresses, ports, countries):\n",
    "        full_proxy = ip_address + \":\" + port\n",
    "\n",
    "        proxy_temp = {\"https\": \"https://\" + full_proxy} #putting it in correct format\n",
    "        print(\"Trying Proxy: \" + \"https://\" + full_proxy)\n",
    "\n",
    "        #Filtering proxies\n",
    "        try:\n",
    "            requests.get(url_testing, proxies=proxy_temp, timeout=timeout_filtering) #Testing proxy by downloading content in URL with a timeout \n",
    "            print(\"Success! Added to List.\") #Successful downloading means that the proxy works\n",
    "            good_proxies.append(full_proxy)\n",
    "            good_proxies_country.append(country)\n",
    "        except:\n",
    "            print(\"Connection error. Trying next proxy.\")\n",
    "    \n",
    "    return good_proxies, good_proxies_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Proxy Collection here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Proxy: https://139.99.105.5:80\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://54.214.52.181:80\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://69.195.157.162:8100\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://209.190.32.28:3128\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://144.217.101.245:3129\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://50.233.228.147:8080\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://198.55.103.233:80\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://64.71.145.122:3128\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://188.227.58.58:3128\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://24.172.34.114:49920\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://107.178.4.215:35330\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://136.25.2.43:56726\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://173.82.177.226:5836\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://198.204.253.114:3128\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://192.3.31.67:9998\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://162.17.252.5:43764\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://34.105.59.26:80\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://3.135.90.78:17567\n",
      "Success! Added to List.\n",
      "Trying Proxy: https://50.192.195.69:52018\n",
      "Success! Added to List.\n"
     ]
    }
   ],
   "source": [
    "url_testing = 'http://www.foo.com/' #URL we'll use to check if a proxy works. Put your desired url to scrape here for best results.\n",
    "timeout_filtering = 4 #seconds, the timer we'll set on checking url_testing with proxies\n",
    "\n",
    "### We will use the 'proxyscrape' module for scraping proxies. Documentation here: https://pypi.org/project/proxyscrape/ ###\n",
    "\n",
    "#Initialize collector for proxies. RUN THIS ONCE.\n",
    "collector = create_collector('my-collector', 'https')\n",
    "\n",
    "#Retrieve a collector if already initialized\n",
    "# collector = get_collector('my-collector')\n",
    "\n",
    "#Outputs a list of working proxies and their corresponding geolocation (country)\n",
    "good_proxies, good_proxies_country  = scrape_proxies(collector, timeout_filtering, url_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display collected proxies in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proxy</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>139.99.105.5:80</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54.214.52.181:80</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>69.195.157.162:8100</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>209.190.32.28:3128</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>144.217.101.245:3129</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>50.233.228.147:8080</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>198.55.103.233:80</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>64.71.145.122:3128</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>188.227.58.58:3128</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>24.172.34.114:49920</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>107.178.4.215:35330</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>136.25.2.43:56726</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>173.82.177.226:5836</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>198.204.253.114:3128</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>192.3.31.67:9998</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>162.17.252.5:43764</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>34.105.59.26:80</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.135.90.78:17567</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>50.192.195.69:52018</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Proxy        Country\n",
       "0        139.99.105.5:80         canada\n",
       "1       54.214.52.181:80  united states\n",
       "2    69.195.157.162:8100  united states\n",
       "3     209.190.32.28:3128  united states\n",
       "4   144.217.101.245:3129         canada\n",
       "5    50.233.228.147:8080  united states\n",
       "6      198.55.103.233:80  united states\n",
       "7     64.71.145.122:3128  united states\n",
       "8     188.227.58.58:3128  united states\n",
       "9    24.172.34.114:49920  united states\n",
       "10   107.178.4.215:35330  united states\n",
       "11     136.25.2.43:56726  united states\n",
       "12   173.82.177.226:5836  united states\n",
       "13  198.204.253.114:3128  united states\n",
       "14      192.3.31.67:9998  united states\n",
       "15    162.17.252.5:43764  united states\n",
       "16       34.105.59.26:80  united states\n",
       "17     3.135.90.78:17567  united states\n",
       "18   50.192.195.69:52018  united states"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(good_proxies, good_proxies_country)), \n",
    "               columns =['Proxy', 'Country']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust web surfing Function with Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_get(browser, url, current_proxy, good_proxies, timeout_sel): \n",
    "    \n",
    "    #Put current proxy on top of list for iteration\n",
    "    if current_proxy in good_proxies:\n",
    "        good_proxies.insert(0, good_proxies.pop(good_proxies.index(current_proxy)))\n",
    "    else:\n",
    "        good_proxies.insert(0,current_proxy) \n",
    "        \n",
    "    for proxy in good_proxies:\n",
    "        \n",
    "        print(\"===================== SURFING =====================\") \n",
    "        \n",
    "        try:\n",
    "            if proxy == current_proxy:\n",
    "                print(\"Current Proxy: \" + proxy)\n",
    "            \n",
    "            if proxy != current_proxy:\n",
    "                print(\"Trying proxy: \" + proxy)\n",
    "                chrome_options = Options() \n",
    "                chrome_options.add_argument('--proxy-server=%s' % proxy)\n",
    "                browser = webdriver.Chrome(chromedriver, options=chrome_options)\n",
    "            \n",
    "            browser.set_page_load_timeout(timeout_sel) #Setting the timer    \n",
    "            browser.get(url)\n",
    "\n",
    "            #error thrown if timer runs out or the browser shows an error is thrown\n",
    "            errorElems = browser.find_elements_by_class_name('neterror')\n",
    "            if len(errorElems) > 0:\n",
    "                raise Exception()\n",
    "                \n",
    "            #Proxy works!\n",
    "            if proxy == current_proxy:\n",
    "                print(\"Still works: \" + proxy)\n",
    "            else:\n",
    "                print(\"Found new working proxy: \" + proxy)\n",
    "                \n",
    "            checker = True\n",
    "            current_proxy = proxy\n",
    "            break\n",
    "        except:\n",
    "            checker = False\n",
    "            print(\"Connection error. Trying next proxy.\")\n",
    "            browser.quit() #Have to close browser in order to change proxy\n",
    "            continue \n",
    "            \n",
    "    if checker == False:\n",
    "        raise Exception(\"No working proxies!\") #Error thrown if none of the proxies are working\n",
    "    else:\n",
    "        print(\"Final proxy: \" + current_proxy)\n",
    "        \n",
    "    return browser, current_proxy #return browser with new working proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Selenium web surfing example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== SURFING =====================\n",
      "Current Proxy: 162.17.252.5:43764\n",
      "Connection error. Trying next proxy.\n",
      "===================== SURFING =====================\n",
      "Trying proxy: 139.99.105.5:80\n",
      "Connection error. Trying next proxy.\n",
      "===================== SURFING =====================\n",
      "Trying proxy: 54.214.52.181:80\n",
      "Found new working proxy: 54.214.52.181:80\n",
      "Final proxy: 54.214.52.181:80\n"
     ]
    }
   ],
   "source": [
    "#Set up the web driver with an initial/preferred proxy\n",
    "preferred_proxy = random.choice(good_proxies) #Just picking a random one from list\n",
    "chromedriver = r'C:/Users/talha/Documents/Chrome_Webdriver/chromedriver.exe'\n",
    "chrome_options = Options()   \n",
    "chrome_options.add_argument('--proxy-server=%s' % preferred_proxy) #with preferred proxy\n",
    "browser = webdriver.Chrome(chromedriver, options=chrome_options)\n",
    "\n",
    "url = 'http://www.foo.com/' #url you want to navigate to\n",
    "timeout_sel = 30 #seconds, the timer set on checking if you can navigate to the url with a proxy\n",
    "\n",
    "#Instead of browser.get(url), you will run this:\n",
    "browser, preferred_proxy = robust_get(browser, url, preferred_proxy, good_proxies, timeout_sel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
